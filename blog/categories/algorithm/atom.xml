<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Algorithm | Personal Interview Notes]]></title>
  <link href="http://tdongsi.github.io/SqlTests/blog/categories/algorithm/atom.xml" rel="self"/>
  <link href="http://tdongsi.github.io/SqlTests/"/>
  <updated>2021-06-26T00:10:16-07:00</updated>
  <id>http://tdongsi.github.io/SqlTests/</id>
  <author>
    <name><![CDATA[Cuong Dong-Si]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Graph Data Structures]]></title>
    <link href="http://tdongsi.github.io/SqlTests/blog/2015/05/02/graph-data-structures/"/>
    <updated>2015-05-02T10:54:59-07:00</updated>
    <id>http://tdongsi.github.io/SqlTests/blog/2015/05/02/graph-data-structures</id>
    <content type="html"><![CDATA[<p>Summary of chapter 14 &ldquo;Graph Algorithms&rdquo; in &ldquo;Data Structures &amp; Algorithms in Python&rdquo; by GTG.</p>

<!--more-->


<h3>Vertices and Edges</h3>

<pre><code class="python Vertex">class Vertex:
    """Lightweight vertex structure for graph"""
    __slots__ = "_element"

    def __init__(self, x):
        self._element = x

    def element(self):
        return self._element

    def __hash__(self):
        return hash(id(self))

    def __str__(self):
        return "[Vertex: %s]" % self._element
</code></pre>

<pre><code class="python Edge">class Edge:
    """Lightweight edge structure for graph"""
    __slots__ = "_src", "_des", "_element"

    def __init__(self, u, v, x):
        self._src = u  # source
        self._des = v  # destination
        self._element = x

    def endpoints(self):
        return self._src, self._des

    def opposite(self, u):
        if u is self._src:
            return self._des
        elif u is self._des:
            return self._src
        else:
            raise ValueError("Unknown vertex")

    def element(self):
        return self._element

    def set_element(self, val):
        self._element = val
        pass

    def __hash__(self):
        return hash((self._src, self._des))

    def __str__(self):
        return "%s &gt;- %s -&gt; %s" % (self._src, self._element, self._des)
</code></pre>

<h3>Graph</h3>

<pre><code class="python Graph">class Graph:
    """Simple graph using an adjancency map"""

    def __init__(self, directed=False):
        self._outgoing = {}
        # Only create the second map for directed graph
        self._incoming = {} if directed else self._outgoing

    def is_directed(self):
        return self._outgoing is not self._incoming

    def vertex_count(self):
        """Return the number of vertices in the graph"""
        return len(self._outgoing)

    def vertices(self):
        """Return the iteration of all vertices"""
        return self._outgoing.keys()

    def edge_count(self):
        """Return the number of edges"""
        total = sum([len(self._outgoing[v]) for v in self.vertices()])
        return total if self.is_directed() else total//2

    def edges(self):
        """Return the iteration of all edges"""
        result = set()
        for secondary_map in self._outgoing.values():
            result.update(secondary_map.values())
        return result

    def get_edge(self, u, v):
        # TRICKY: self._outgoing[u][v] will raise KeyError instead of None if (u,v) not found
        return self._outgoing[u].get(v)

    def degree(self, v, outgoing=True):
        if outgoing:
            return len(self._outgoing[v])
        else:
            return len(self._incoming[v])

    def incident_edges(self, v, outgoing=True):
        """Return an *iteration* of incident edges"""
        adj = self._outgoing if outgoing else self._incoming
        for e in adj[v].values():
            yield e

    def insert_vertex(self, x=None):
        v = Vertex(x)
        self._outgoing[v] = {}
        if self.is_directed():
            self._incoming[v] = {}
        return v

    def insert_edge(self, u, v, x=None):
        e = Edge(u, v, x)
        self._outgoing[u][v] = e
        self._incoming[v][u] = e
        return e

    def delete_edge(self, u, v):
        del self._outgoing[u][v]
        del self._incoming[v][u]
        pass
</code></pre>

<h3>Modifications for Network Flows</h3>

<p>Note that for Network Flow problem, we must add <code>set_element</code> to Edge class and <code>delete_edge</code> to Graph class.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Graph Data Algorithms]]></title>
    <link href="http://tdongsi.github.io/SqlTests/blog/2015/05/01/graph-algorithms/"/>
    <updated>2015-05-01T03:12:53-07:00</updated>
    <id>http://tdongsi.github.io/SqlTests/blog/2015/05/01/graph-algorithms</id>
    <content type="html"><![CDATA[<p>Summary of chapter 14 &ldquo;Graph Algorithms&rdquo; in &ldquo;Data Structures &amp; Algorithms in Python&rdquo; by GTG.</p>

<!--more-->


<h3>Graph traversals</h3>

<h4>BFS</h4>

<pre><code class="python Book version">def BFS(g:Graph, s:Vertex, discovered):
    """ BFS traversal of the undiscovered portion of Graph g starting at vertex s.

    :param g: give Graph
    :param s: starting Vertex
    :param discovered: Mapping each vertex to the edge used to discover it.
    :return:
    """
    level = [s]

    while len(level) &gt; 0:
        next_level = []
        for v in level:
            for e in g.incident_edges(v):
                u = e.opposite(v)
                if u not in discovered:
                    discovered[u] = e
                    next_level.append(u)

        level = next_level
</code></pre>

<pre><code class="python Construct path">def construct_path(u:Vertex, v:Vertex, discovered):
    """ Construct a path from u to v."""
    path = []

    if v in discovered:
        path.append(v)

        walk = v
        while walk is not u:
            e = discovered[walk]
            parent = e.opposite(walk)
            path.append(parent)
            walk = parent

        path.reverse()

    return path
</code></pre>

<h3>Transitive Closure</h3>

<p>Background: If the graph representation is adjacency list or adjacency map, we can answer the question of reachability for any u and v in <code>O(n+m)</code> (where <code>n</code> is the number of nodes, <code>m</code> is the number of edges).
However, if you have to answer <strong>many</strong> reachability queries (e.g., navigation application), it is better to construct a transitive closure for that graph.</p>

<p>A transitive closure <code>G'</code> is for a directed graph <code>G</code>: any u and v that are reachable, there is an edge (u, v) in <code>Gâ€™</code>.</p>

<p>In the classic adjacency list or adjacency map representation, transitive closure can be constructed in <code>O(n(n+m))</code> by repeating DFS at each vertex.
However, when the graph is dense (m -> n<sup>2</sup>), you is better off with Floyd-Warshall algorithm <code>O(n^3)</code> using <strong>adjacency matrix</strong> representation.
Floyd-Warshall requires get_edge and insert_edge to be done in <code>O(1)</code> time, which necessitates adjacency matrix requirements.</p>

<p>In theory, <code>O(n^3)</code> is not better than repeated DFS traversals <code>O(n(n+m))</code>.
However, in practice, Floyd-Warshall is faster and easier to implement because there are fewer low-level operations.
However, when the graph is sparse, repeated DFS traversal approach is better in time and space complexity.</p>

<pre><code class="python Floyd-Warshall implementation">def floyd_warshall(g:Graph) -&gt; Graph:
    """ Return a new graph that is the transite closure of g.

    :param g: input graph
    :return: the transitive closure of g.
    """
    closure = deepcopy(g)
    verts = list(closure.vertices())
    n = len(verts)

    for k in range(n):
        for i in range(n):
            # verify that edge(i, k) exists in the partial closure
            if i != k and closure.get_edge(verts[i], verts[k]) is not None:
                for j in range(n):
                    # verify that edge(k, j) exists in the partial closure
                    if i != j != k and closure.get_edge(verts[k], verts[j]) is not None:
                        if closure.get_edge(verts[i], verts[j]) is None:
                            # if (i, j) not yet included, add it to the closure
                            closure.insert_edge(verts[i], verts[j])

    return closure
</code></pre>

<h3>DAG and topological sorting.</h3>

<p>A directed graph may have more than one topological ordering.</p>

<blockquote><p><strong>Proposition</strong>: A directed graph has a topological sorting if and only if it is acyclic.</p></blockquote>

<pre><code class="python Topological sorting">def topological_sort(g: Graph) -&gt; list:
    """ Return a list of vertices of DAG in topological order

    :param g: a directed acyclic graph (DAG)
    :return: list of topological sort
    """
    topo = []
    ready = []
    incount = {}

    for u in g.vertices():
        incount[u] = g.degree(u, False)
        if incount[u] == 0:
            # u is free of constraints
            ready.append(u)

    while len(ready) &gt; 0:
        u = ready.pop()
        topo.append(u)

        for e in g.incident_edges(u):
            v = e.opposite(u)
            incount[v] -= 1
            if incount[v] == 0:
                ready.append(v)

    return topo
</code></pre>

<h3>Shortest Paths</h3>

<p>We have a few choices for implementing &ldquo;adaptable priority queue with location-aware entries&rdquo; (at least <code>remove_min</code> required) in Dijkstra&rsquo;s algorithm:</p>

<ul>
<li>Unsorted sequence implementation -> <code>O(n^2 +m)</code> runtime.</li>
<li>A heap implementation -> <code>O( (n+m)log(n) )</code> runtime.</li>
<li>Fibonacci heap implementation -> <code>O(m +nlog(n))</code> runtime.</li>
</ul>


<p>The &ldquo;heap implementation&rdquo; is &ldquo;AdaptableHeapPriorityQueue&rdquo; class from the chapter 9 of the same textbook.
The &ldquo;Unsorted sequence implementation&rdquo; is implemented as follows, using the same signature of the above class for later compatibility:</p>

<pre><code class="python Simple Adaptable Priority Queue implementation">class AdaptableUnsortedPriorityQueue():
    """ Mocking AdaptableHeapPriorityQueue.
    loc =&gt; key in internal map
    key, val =&gt; value in internal map
    """

    def __init__(self):
        self._map = {}

    def add(self, key, value):
        """Add a key-value pair."""
        self._map[value] = (key, value)
        return value

    def update(self, loc, newkey, newval):
        """Update the key and value for the entry"""
        self._map[loc] = (newkey, newval)

    def is_empty(self):
        return (len(self._map) == 0)

    def remove_min(self):

        min_key = float('inf')
        min_loc = None
        min_return = None

        for loc, val in self._map.items():
            if val[0] &lt; min_key:
                min_key = val[0]
                min_loc = loc
                min_return = val

        del self._map[min_loc]
        return min_return
</code></pre>

<p>Python implementation of Dijkstra&rsquo;s algorithm is shown below.
Dijkstra&rsquo;s algorithm is analogous to a weighted BFS traversal.
A few assumptions must be true in this implementation:</p>

<ul>
<li>Theoretical requirement: All the weights are nonnegative.</li>
<li><code>e.element()</code> returns the weight of the edge.</li>
</ul>


<pre><code class="python Dijkstra's algorithm">def shortest_path_lengths(g:Graph, s:Vertex):
    """ Compute shortest-path distances from src to reachable vertices of g.
    Dijkstra's Algorithm for finding shortest paths.

    :param g: directed or undirected Graph. e.element() must return non-negative weight
    :param s: Starting vertex
    :return: dictionary mapping each reachable vertex to its distance from s.
    """

    d = {}      # d[v] is upper bound from s to v
    cloud = {}  # map reachable v to its d[v] value
    pq = AdaptableUnsortedPriorityQueue()   # vertex v will have key d[v]
    pqlocator = {}      # map from vertex to its pq locator

    for v in g.vertices():
        if v is s:
            d[v] = 0
        else:
            d[v] = float('inf')

        pqlocator[v] = pq.add(d[v], v)

    while not pq.is_empty():
        key, u = pq.remove_min()
        cloud[u] = key

        for e in g.incident_edges(u):
            v = e.opposite(u)
            if v not in cloud:
                wgt = e.element()
                if d[u] + wgt &lt; d[v]:
                    d[v] = d[u] + wgt
                    pq.update(pqlocator[v], d[v], v)

    return cloud
</code></pre>

<p>Then, based on the returned computed shortest-path distances, we can compute <strong>shortest-path tree</strong>.
We use the same data structure that represents <strong>DFS tree</strong> and <strong>BFS tree</strong>: a map that maps a vertex to its discovery edge (edge connecting to its parent).
Because of using the same data structure, you can reuse the method <code>construct_path</code> to compute the path from one vertex to another.</p>

<pre><code class="python Compute shortest path tree">def shortest_path_tree(g: Graph, s: Vertex, d:dict) -&gt; dict:
    """ Reconstruct shortest-path tree rooted at vertex s, given the distance map d.
    Return tree as a map from vertex v -&gt; discovery edge.

    :param g: Given graph, directed or undirected.
    :param s: starting vertex.
    :param d: distance map, created from Dijkstra's algorithm.
    :return:
    """
    tree = {}

    for v in d:
        if v is not s:
            for e in g.incident_edges(v, False):
                u = e.opposite(v)
                wgt = e.element()
                if d[v] == d[u] + wgt:
                    tree[v] = e

    return tree
</code></pre>

<p>Example usage:</p>

<pre><code class="python Example usage">def test_dijkstra_algorithm(self):
    g = ExampleGraphs.airport_graph()

    vertex_map = {v.element() : v for v in g.vertices()}
    starting_vertex = vertex_map["JFK"]

    cloud = shortest_path_lengths(g, starting_vertex)

    for k, v in cloud.items():
        print("%s: %s"% (k,v))

    sp_tree = shortest_path_tree(g, starting_vertex, cloud)
    path = construct_path(vertex_map["JFK"], vertex_map["LAX"], sp_tree)

    print("Shortest path from JFK to LAX")
    for ap in path:
        print(str(ap))
</code></pre>

<pre><code class="plain Example output">Shortest path from JFK to LAX
[Vertex: JFK]
[Vertex: ORD]
[Vertex: DFW]
[Vertex: LAX]
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Network Flow: Basics]]></title>
    <link href="http://tdongsi.github.io/SqlTests/blog/2015/04/11/network-flow-basics/"/>
    <updated>2015-04-11T18:51:41-07:00</updated>
    <id>http://tdongsi.github.io/SqlTests/blog/2015/04/11/network-flow-basics</id>
    <content type="html"><![CDATA[<p>Summary of chapter 7 &ldquo;Network Flows&rdquo; in &ldquo;Algorithm Design&rdquo; by Kleinberg &amp; Tardos.</p>

<!--more-->


<h3>Network Flow Basics</h3>

<p>Augmenting Path</p>

<pre><code class="plain Augment pseudocode">TODO
</code></pre>

<p>Ford-Fulkerson method</p>

<pre><code class="plain Ford-Fulkerson pseudocode">TODO
</code></pre>

<p>If all capacities in the flow network G are integers, then the Ford-Fulkerson method runs in O(mC) time.</p>

<h3>Capacity-Scaling Algorithm</h3>

<p>Algorithm</p>

<p>Runtime</p>

<h3>Edmonds-Karp Algorithm</h3>

<pre><code class="python Edmonds-Karp variant of Ford-Fulkerson method">def edmonds_karp(g: Graph, source: Vertex, sink: Vertex):
    """ Edmonds-Karp implementation of Ford-Fulkerson method.
    If you have an original network flow, you should create a deep copy of it AND retrieve the right source/sink vertcies.

    :param g: residual graph
    :param source: source Vertex
    :param sink: sink Vertex
    :return: maximum flow
    """

    def BFS_augment_path(g, s, t):
        """ Find BFS path from s to t in network flow graph.

        :param s: source
        :param t: sink
        :return: list of edges from s to t. Empty if there is no path.
        """
        discovered = BFS_iter(g, s)
        vertices = construct_path(s, t, discovered)
        edges = []

        if vertices:
            for i in range(len(vertices)-1):
                edges.append(g.get_edge(vertices[i], vertices[i+1]))

        return edges

    max_flow = 0
    path = BFS_augment_path(g, source, sink)

    while path:

        path_flow = min([e.element() for e in path])
        max_flow += path_flow

        for e in path:
            u, v = e.endpoints()

            # Update forward residual edge
            cur = e.element()
            if cur - path_flow == 0:
                g.delete_edge(u, v)
            else:
                e.set_element(cur - path_flow)

            # Update backward residual edge
            if g.get_edge(v, u) is None:
                g.insert_edge(v, u, path_flow)
            else:
                reverse_edge = g.get_edge(v, u)
                cur = reverse_edge.element()
                reverse_edge.set_element(cur + path_flow)

        path = BFS_augment_path(g, source, sink)

    return max_flow
</code></pre>

<h3>Blocking-Flow Algorithm</h3>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Data Structure: Trie]]></title>
    <link href="http://tdongsi.github.io/SqlTests/blog/2013/05/14/trie-data-structure/"/>
    <updated>2013-05-14T19:10:03-07:00</updated>
    <id>http://tdongsi.github.io/SqlTests/blog/2013/05/14/trie-data-structure</id>
    <content type="html"><![CDATA[<p>TODO: Trie section in GTG&rsquo;s chapter 13.</p>

<!--more-->


<h3>Basic implementation</h3>

<pre><code class="python Trie data structure">class TrieNode():
    __slots__ = 'children', 'word_end', 'size'

    def __init__(self):
        self.children = {}
        self.word_end = False
        self.size = 0


class Trie():

    def __init__(self):
        self._root = TrieNode()

    def insert(self, word):
        current = self._root

        for c in word:
            current.size += 1
            node = current.children.get(c)
            if node is None:
                node = TrieNode()
                current.children[c] = node

            current = node

        # Mark the last one as end of word
        current.size += 1
        current.word_end = True

    def search(self, word):
        """Check if the given word is present"""
        current = self._root

        for c in word:
            node = current.children.get(c)
            if node is None:
                return False
            current = node

        return current.word_end

    def search_partial(self, prefix):
        """Count the number of contacts starting with prefix."""
        current = self._root

        for c in prefix:
            node = current.children.get(c)
            if node is None:
                return 0
            current = node

        return current.size

    def delete(self, word):
        self._delete(self._root, word, 0)

    def _delete(self, current: TrieNode, word: str, idx: int):
        """Return True if parent node should delete the mapping."""
        if idx == len(word):
            if not current.word_end:
                return False

            current.word_end = False
            return len(current.children) == 0

        c = word[idx]
        node = current.children.get(c)
        if node is None:
            return False

        shouldDelete = self._delete(node, word, idx+1)

        if shouldDelete:
            del current.children[c]
            return len(current.children) == 0

        return False

    def list(self):
        return list(self._list(self._root, ""))

    def _list(self, current: TrieNode, prefix: str):
        if current.word_end:
            # print(prefix)
            yield prefix
        else:
            for k in current.children:
                yield from self._list(current.children[k], prefix + k)
</code></pre>

<h3>References</h3>

<ul>
<li><a href="https://github.com/tdongsi/gtg/blob/develop/chapter13/string.py">My Python code</a>.</li>
<li><a href="https://web.archive.org/web/20170307224715/http://googleyasheck.com/fun-with-tries/">Alternative implementation</a>.</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Book: GTG: Text Processing]]></title>
    <link href="http://tdongsi.github.io/SqlTests/blog/2013/04/23/book-gtg-text-processing/"/>
    <updated>2013-04-23T16:34:23-07:00</updated>
    <id>http://tdongsi.github.io/SqlTests/blog/2013/04/23/book-gtg-text-processing</id>
    <content type="html"><![CDATA[<p>Summary of chapter 14 &ldquo;Graph Algorithms&rdquo; in &ldquo;Data Structures &amp; Algorithms in Python&rdquo; by GTG.</p>

<!--more-->


<h3>Pattern-Matching Algorithms</h3>

<p>For the following algorithms, <code>m</code> is the length of the pattern (substring) and <code>n</code> is the length of the larger text.</p>

<h4>Brute-force algorithm</h4>

<p>The brute force running time is <code>O(mn)</code>.</p>

<pre><code class="python Brute Force">def find_brute(text:str, subs: str):
    """ Pattern matching with brute force.
    Return the lowest index of text T at which substring P begins (or else -1).

    :param text: text T
    :param subs: substring P
    :return: lowest index of T
    """
    if not text or not subs:
        return -1

    n, m = len(text), len(subs)

    for i in range(n - m + 1):
        k = 0
        while k &lt; m and text[i+k] == subs[k]:
            k += 1
        if k == m:
            return i

    return -1
</code></pre>

<h4>Boyer-Moore algorithm</h4>

<pre><code class="python Boyer-Moore algorihtm">def find_boyer_moore(text:str, subs:str):
    """ Pattern matching with Boyer-Moore algorithm.
    Return the lowest index of text T at which substring P begins (or else -1).

    :param text: text T
    :param subs: substring P
    :return: lowest index of T
    """
    if not text or not subs:
        return -1

    n, m = len(text), len(subs)

    last = {}
    for k in range(m):
        last[subs[k]] = k

    # align end of pattern at index m-1 of text
    i = m-1  # index into 'text'
    k = m-1  # index into 'subs'
    while i &lt; n:
        if text[i] == subs[k]:  # a matching character
            if k == 0:
                return i  # pattern begins at index i of text
            else:
                i -= 1  # examine previous characters in both T &amp; P
                k -= 1
        else:
            j = last.get(text[i], -1)
            # Sanity check:
            # 1) text[i] not in last -&gt; i += m
            # 2) text[i] in last -&gt; i += m - (j+1)
            i += m - min(k, j+1)
            k = m -1  # restart at end of pattern

    return -1
</code></pre>

<h4>Knuth-Morris-Pratt algorithm.</h4>

<p>The KMP running time is <code>O(m+n)</code>.</p>

<pre><code class="Python KMP algorithm">def compute_kmp_fail(pattern: str):
    """ Utility function that computes and returns KMP failure function.

    :param pattern: the pattern
    :return: list as lookup table
    """
    m = len(pattern)
    fail = [0] * m
    j = 1
    k = 0
    while j &lt; m:
        if pattern[j] == pattern[k]:  # k+1 characters match thus far
            fail[j] = k+1
            j += 1
            k += 1
        elif k &gt; 0:
            k = fail[k-1]
        else:  # no match found starting a j
            j += 1
    return fail


def find_kmp(text: str, subs: str):
    """ Pattern matching with Knuth-Morris-Pratt algorithm.
    Return the lowest index of text T at which substring P begins (or else -1).

    :param text: text T
    :param subs: substring P
    :return: lowest index of T
    """
    if not text or not subs:
        return -1

    n, m = len(text), len(subs)

    fail = compute_kmp_fail(subs)

    j = 0
    k = 0
    while j &lt; n:
        if text[j] == subs[k]:
            if k == m-1:
                return j - m + 1
            j += 1
            k += 1
        elif k &gt; 0:
            k = fail[k-1]
        else:
            j += 1

    return -1
</code></pre>

<h3>DP and Longest Common Subsequence</h3>

<p>See <a href="TODO">here</a>.</p>

<h3>Huffman coding method.</h3>

<p>SKIP.</p>

<h3>Tries</h3>

<p>The idea of tries comes from the fact that text search can be sped up with preprocessing the pattern such as Boyer-More and KMP algorithms.
Such approach is suitable for applications where a series of queries is performed on a fixed text, so that the initial cost of preprocessing is compensated by a speed up in each subsequent query.</p>

<p>A trie is for storing strings in order to support fast pattern matching.
The main application for tries is for information retrieval.
The primary query operations are pattern matching and prefix matching.</p>

<h4>Standard trie</h4>

<p>One key assumption in trie is that no string in S is a prefix of another string.
This ensures that each string in S is uniquely associated with a leaf of T.
We can satisfy this assumption by adding a special termination character (conventionally <code>$</code>) that is not in the alphabet at the end of each string.</p>

<p>Standard operations:</p>

<ul>
<li>Seach for a string of length <code>m</code>: <code>O(m)</code>.

<ul>
<li>Rationale: We visit at most <code>m+1</code> nodes in T and we spend <code>O(1)</code> at each node if we have secondary hash table/lookup table at each node for search.</li>
<li>Only works for exact word matching or prefix matching. Arbitrary substring search does not work.</li>
</ul>
</li>
<li>Construction of trie: <code>O(n)</code>.

<ul>
<li><code>n</code> is the total length of the strings in S.</li>
</ul>
</li>
</ul>


<h4>Compressed trie</h4>

<p>Compressed trie is also known as Patricia trie for historical reasons.
Each internal node of compressed trie has at least two children.
It enforces this rule by compressing chains of single-child nodes into individual edges.
Nodes in compressed trie are labeled with strings instead of single characters as in standard trie.
The advantange of compressed trie is that the number of nodes of the compressed trie is proportional to number of strings, instead of its total length.</p>

<p>The real space savings come when it is used as auxiliary index structure over a collection of strings already stored in some other primary structure.
Then, we can use numeric indexes in trie instead of storing actual characters.
Searching in a compressed trie is not actually faster than a standard trie.</p>

<h4>Suffix Trie</h4>

<p>More info at <a href="https://www.youtube.com/watch?v=N70NPX6xgsA">here</a>.</p>

<p>A suffix trie is a compressed trie containing all the suffixes of the given text X of size <code>n</code> from an alphabet of size <code>d</code>.
Note that trivially storing all the suffixes of an X would take <code>O(n^2)</code> space.
However, the compact representation of a compressed trie is proportional to number of strings and uses <code>O(n)</code> space instead.
It can be constructed with a specialized algorithm in <code>O(dn)</code> time (not discussed in book).
The standard trie construction would take <code>O(d*n^2)</code> time.</p>

<p>Standard operations:</p>

<ul>
<li>Seach for a pattern/prefix of length <code>m</code>: <code>O(dm)</code>.</li>
</ul>


<p>Applications:</p>

<ul>
<li>Pattern/Prefix searching</li>
<li>Exact string matching</li>
<li>Finding the longest repeated substring</li>
<li>Finding the longest palindrome in a string: Manacher&rsquo;s algorithm.</li>
<li>Lowest common ancestors</li>
<li>Finding the longest commont substring</li>
</ul>


<h4>Search Engine Indexing</h4>

<p>The core information stored by a search engine is a dictionary, called an <strong>inverted index</strong> or <strong>inverted file</strong>, storing the following key-value pairs:</p>

<ul>
<li>keys: words (index terms)</li>
<li>values: occurrence lists: collection of pages containing the corresponding key word.</li>
</ul>


<p>We can implement the inverted file with a data structure consisting of the following:</p>

<ul>
<li>A compressed trie for the set of keys (index terms), where each leaf stores the index of the occurence list.</li>
<li>An array storing the occurrence lists of the terms.</li>
</ul>


<p>The compressed trie can be fit into the memory while the much larger array for the occurrence lists can be stored on disk.</p>

<p>A query for a single keyword is similar to a word-matching query.
Namely, we find the keyword in the trie and we return the associated occurrence list.
When multiple words are given and the desired output are the pages containing all the given keywords, we retrieve all the occurrence lists and find their intersection.
Note that for a real search engine, additional service must be provided such as ranking the pages returned by relevance.</p>
]]></content>
  </entry>
  
</feed>
