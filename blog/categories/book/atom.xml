<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Book | Personal Interview Notes]]></title>
  <link href="http://tdongsi.github.io/SqlTests/blog/categories/book/atom.xml" rel="self"/>
  <link href="http://tdongsi.github.io/SqlTests/"/>
  <updated>2018-03-11T19:19:08-07:00</updated>
  <id>http://tdongsi.github.io/SqlTests/</id>
  <author>
    <name><![CDATA[Cuong Dong-Si]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Graph Data Structures & Algorithms]]></title>
    <link href="http://tdongsi.github.io/SqlTests/blog/2016/05/01/graph-algorithms/"/>
    <updated>2016-05-01T03:12:53-07:00</updated>
    <id>http://tdongsi.github.io/SqlTests/blog/2016/05/01/graph-algorithms</id>
    <content type="html"><![CDATA[<p>Summary of chapter 14 &ldquo;Graph Algorithms&rdquo; in &ldquo;Data Structures &amp; Algorithms in Python&rdquo; by GTG.</p>

<!--more-->


<h3>Graph traversals</h3>

<h4>BFS</h4>

<pre><code class="python Book version">def BFS(g:Graph, s:Vertex, discovered):
    """ BFS traversal of the undiscovered portion of Graph g starting at vertex s.

    :param g: give Graph
    :param s: starting Vertex
    :param discovered: Mapping each vertex to the edge used to discover it.
    :return:
    """
    level = [s]

    while len(level) &gt; 0:
        next_level = []
        for v in level:
            for e in g.incident_edges(v):
                u = e.opposite(v)
                if u not in discovered:
                    discovered[u] = e
                    next_level.append(u)

        level = next_level
</code></pre>

<h3>Transitive Closure</h3>

<p>Background: If the graph representation is adjacency list or adjacency map, we can answer the question of reachability for any u and v in <code>O(n+m)</code> (where <code>n</code> is the number of nodes, <code>m</code> is the number of edges).
However, if you have to answer <strong>many</strong> reachability queries (e.g., navigation application), it is better to construct a transitive closure for that graph.</p>

<p>A transitive closure <code>G'</code> is for a directed graph <code>G</code>: any u and v that are reachable, there is an edge (u, v) in <code>Gâ€™</code>.</p>

<p>In the classic adjacency list or adjacency map representation, transitive closure can be constructed in <code>O(n(n+m))</code> by repeating DFS at each vertex.
However, when the graph is dense (m -> n<sup>2</sup>), you is better off with Floyd-Warshall algorithm <code>O(n^3)</code> using <strong>adjacency matrix</strong> representation.
Floyd-Warshall requires get_edge and insert_edge to be done in <code>O(1)</code> time, which necessitates adjacency matrix requirements.</p>

<p>In theory, <code>O(n^3)</code> is not better than repeated DFS traversals <code>O(n(n+m))</code>.
However, in practice, Floyd-Warshall is faster and easier to implement because there are fewer low-level operations.
However, when the graph is sparse, repeated DFS traversal approach is better in time and space complexity.</p>

<pre><code class="python Floyd-Warshall implementation">def floyd_warshall(g:Graph) -&gt; Graph:
    """ Return a new graph that is the transite closure of g.

    :param g: input graph
    :return: the transitive closure of g.
    """
    closure = deepcopy(g)
    verts = list(closure.vertices())
    n = len(verts)

    for k in range(n):
        for i in range(n):
            # verify that edge(i, k) exists in the partial closure
            if i != k and closure.get_edge(verts[i], verts[k]) is not None:
                for j in range(n):
                    # verify that edge(k, j) exists in the partial closure
                    if i != j != k and closure.get_edge(verts[k], verts[j]) is not None:
                        if closure.get_edge(verts[i], verts[j]) is None:
                            # if (i, j) not yet included, add it to the closure
                            closure.insert_edge(verts[i], verts[j])

    return closure
</code></pre>

<h3>DAG and topological sorting.</h3>

<p>A directed graph may have more than one topological ordering.</p>

<blockquote><p><strong>Proposition</strong>: A directed graph has a topological sorting if and only if it is acyclic.</p></blockquote>

<pre><code class="python Topological sorting">def topological_sort(g: Graph) -&gt; list:
    """ Return a list of vertices of DAG in topological order

    :param g: a directed acyclic graph (DAG)
    :return: list of topological sort
    """
    topo = []
    ready = []
    incount = {}

    for u in g.vertices():
        incount[u] = g.degree(u, False)
        if incount[u] == 0:
            # u is free of constraints
            ready.append(u)

    while len(ready) &gt; 0:
        u = ready.pop()
        topo.append(u)

        for e in g.incident_edges(u):
            v = e.opposite(u)
            incount[v] -= 1
            if incount[v] == 0:
                ready.append(v)

    return topo
</code></pre>

<h3>Shortest Paths</h3>

<p>We have a few choices for implementing &ldquo;adaptable priority queue with location-aware entries&rdquo; (at least <code>remove_min</code> required) in Dijkstra&rsquo;s algorithm:</p>

<ul>
<li>Unsorted sequence implementation -> <code>O(n^2 +m)</code> runtime.</li>
<li>A heap implementation -> <code>O( (n+m)log(n) )</code> runtime.</li>
<li>Fibonacci heap implementation -> <code>O(m +nlog(n))</code> runtime.</li>
</ul>


<p>The &ldquo;heap implementation&rdquo; is &ldquo;AdaptableHeapPriorityQueue&rdquo; class from the chapter 9 of the same textbook.
The &ldquo;Unsorted sequence implementation&rdquo; is implemented as follows, using the same signature of the above class for later compatibility:</p>

<pre><code class="python Simple Adaptable Priority Queue implementation">class AdaptableUnsortedPriorityQueue():
    """ Mocking AdaptableHeapPriorityQueue.
    loc =&gt; key in internal map
    key, val =&gt; value in internal map
    """

    def __init__(self):
        self._map = {}

    def add(self, key, value):
        """Add a key-value pair."""
        self._map[value] = (key, value)
        return value

    def update(self, loc, newkey, newval):
        """Update the key and value for the entry"""
        self._map[loc] = (newkey, newval)

    def is_empty(self):
        return (len(self._map) == 0)

    def remove_min(self):

        min_key = float('inf')
        min_loc = None
        min_return = None

        for loc, val in self._map.items():
            if val[0] &lt; min_key:
                min_key = val[0]
                min_loc = loc
                min_return = val

        del self._map[min_loc]
        return min_return
</code></pre>

<p>Python implementation of Dijkstra&rsquo;s algorithm is shown below.
Dijkstra&rsquo;s algorithm is analogous to a weighted BFS traversal.
A few assumptions must be true in this implementation:</p>

<ul>
<li>Theoretical requirement: All the weights are nonnegative.</li>
<li><code>e.element()</code> returns the weight of the edge.</li>
</ul>


<pre><code class="python Dijkstra's algorithm">def shortest_path_lengths(g:Graph, s:Vertex):
    """ Compute shortest-path distances from src to reachable vertices of g.
    Dijkstra's Algorithm for finding shortest paths.

    :param g: directed or undirected Graph. e.element() must return non-negative weight
    :param s: Starting vertex
    :return: dictionary mapping each reachable vertex to its distance from s.
    """

    d = {}      # d[v] is upper bound from s to v
    cloud = {}  # map reachable v to its d[v] value
    pq = AdaptableUnsortedPriorityQueue()   # vertex v will have key d[v]
    pqlocator = {}      # map from vertex to its pq locator

    for v in g.vertices():
        if v is s:
            d[v] = 0
        else:
            d[v] = float('inf')

        pqlocator[v] = pq.add(d[v], v)

    while not pq.is_empty():
        key, u = pq.remove_min()
        cloud[u] = key

        for e in g.incident_edges(u):
            v = e.opposite(u)
            if v not in cloud:
                wgt = e.element()
                if d[u] + wgt &lt; d[v]:
                    d[v] = d[u] + wgt
                    pq.update(pqlocator[v], d[v], v)

    return cloud
</code></pre>

<p>Then, based on the returned computed shortest-path distances, we can compute <strong>shortest-path tree</strong>.
We use the same data structure that represents <strong>DFS tree</strong> and <strong>BFS tree</strong>: a map that maps a vertex to its discovery edge (edge connecting to its parent).
Because of using the same data structure, you can reuse the method <code>construct_path</code> to compute the path from one vertex to another.</p>

<pre><code class="python Compute shortest path tree">def shortest_path_tree(g: Graph, s: Vertex, d:dict) -&gt; dict:
    """ Reconstruct shortest-path tree rooted at vertex s, given the distance map d.
    Return tree as a map from vertex v -&gt; discovery edge.

    :param g: Given graph, directed or undirected.
    :param s: starting vertex.
    :param d: distance map, created from Dijkstra's algorithm.
    :return:
    """
    tree = {}

    for v in d:
        if v is not s:
            for e in g.incident_edges(v, False):
                u = e.opposite(v)
                wgt = e.element()
                if d[v] == d[u] + wgt:
                    tree[v] = e

    return tree
</code></pre>

<p>Example usage:</p>

<pre><code class="python Example usage">def test_dijkstra_algorithm(self):
    g = ExampleGraphs.airport_graph()

    vertex_map = {v.element() : v for v in g.vertices()}
    starting_vertex = vertex_map["JFK"]

    cloud = shortest_path_lengths(g, starting_vertex)

    for k, v in cloud.items():
        print("%s: %s"% (k,v))

    sp_tree = shortest_path_tree(g, starting_vertex, cloud)
    path = construct_path(vertex_map["JFK"], vertex_map["LAX"], sp_tree)

    print("Shortest path from JFK to LAX")
    for ap in path:
        print(str(ap))
</code></pre>

<pre><code class="plain Example output">Shortest path from JFK to LAX
[Vertex: JFK]
[Vertex: ORD]
[Vertex: DFW]
[Vertex: LAX]
</code></pre>
]]></content>
  </entry>
  
</feed>
