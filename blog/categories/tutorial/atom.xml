<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Tutorial | Personal Interview Notes]]></title>
  <link href="http://tdongsi.github.io/SqlTests/blog/categories/tutorial/atom.xml" rel="self"/>
  <link href="http://tdongsi.github.io/SqlTests/"/>
  <updated>2017-01-15T19:11:50-08:00</updated>
  <id>http://tdongsi.github.io/SqlTests/</id>
  <author>
    <name><![CDATA[Cuong Dong-Si]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Tutorial: Dashboard for Business Analytics]]></title>
    <link href="http://tdongsi.github.io/SqlTests/blog/2016/09/16/tutorial-dashboard-for-business-analytics/"/>
    <updated>2016-09-16T15:40:35-07:00</updated>
    <id>http://tdongsi.github.io/SqlTests/blog/2016/09/16/tutorial-dashboard-for-business-analytics</id>
    <content type="html"><![CDATA[<p>Summary of &ldquo;Business Dashboard Fundamentals&rdquo; on Pluralsight.</p>

<!--more-->


<h3>General guidelines for dashboard</h3>

<p>Ppl looks for different things in data. You have to find out what answers users look for in dashboard.</p>

<ul>
<li>Trend: bar, graph</li>
<li>Aggregation: Average, Sum, Max, Min.</li>
</ul>


<p>Above all else, show data.
Trying to improve data-pixel ratio: data pixels/non-data pixels.
How to enhance data-pixel ratio:</p>

<ul>
<li>Granularity: depends on the question you want to answer

<ul>
<li>monthly if you want to know monthly sales, daily if you want to know what happens last Tuesday.</li>
<li>category or sub-category: you can have category with drill down function.</li>
</ul>
</li>
<li>Annotation: similar to Granularity. Minimize it to enough to answer the question.</li>
</ul>


<p>Tricks &amp; Tips:</p>

<ul>
<li>Plots (over Bars): plot show the trends for different components over time.</li>
<li>Sizing Bars: Preserve True Portions: starting Y from 0.

<ul>
<li>Sizing Bars: shows proportions, relative progression.</li>
</ul>
</li>
<li>Scatter Plots: show clusters, outliers.</li>
<li>Radio displays: usually a bad idea. Waste of space, hard to discern between slices.</li>
</ul>


<h3>Module 2: Common Charts</h3>

<p>Basic data Presentation Methods - Chart Types</p>

<ul>
<li>Geo-Spatial - Maps: anything related to geographic distribution, i.e., when geography matters. e.g. real estates, oil industry.</li>
<li>Correlation - Scatter Plots: two measurements (e.g., sales to profit).</li>
<li>Hierarchical - Drill down Tree: data is hierarchical: Category -> Subcateogries.</li>
<li>Categorical - Bar Charts: comparing categories (sales by region)</li>
<li>Time Series - Line Charts: progression over time. (sales by month)

<ul>
<li>Avoid: Stacked Area Charts. If you have more than two lines, Area Charts do not give any information except for the bottom and the total.</li>
</ul>
</li>
<li>Distribution - Histograms: Trying to answer what is “normal”. e.g., home prices, salaries.</li>
</ul>


<p>Others</p>

<ul>
<li>Box plot: distribution, percentiles, median in 1 chart.</li>
<li>Bullet graph: actuals to target. Invented by Stephen Few.

<ul>
<li>Dark bar is actual, reference line is target. Color code bands are average, good, bad target range.</li>
<li><a href="https://en.wikipedia.org/wiki/Bullet_graph">https://en.wikipedia.org/wiki/Bullet_graph</a></li>
</ul>
</li>
<li>Sparkline: Multiple line charts. Best used for monitoring dashboard.</li>
<li>Heat map: Large combinations of dimensions. Color is everything here.</li>
</ul>


<p>Charts to avoid</p>

<ul>
<li>Pie charts: angles make it hard to compare. Usually decorative, not informative. Space is wasted.</li>
<li>Polar charts</li>
<li>Stacked area charts:

<ul>
<li>Only tell the story of the bottom line and the total. Anything in between, you can’t really tell if they are growing or not.</li>
<li>Misleading/Confusing: is the top the total or another category?</li>
</ul>
</li>
</ul>


<h3>Module 3: Dashboard planning</h3>

<p>Steps:</p>

<ul>
<li>User Request</li>
<li>Prioritization</li>
<li>Planning</li>
<li>Design</li>
<li>Development</li>
<li>Delivery to User</li>
</ul>


<h3>Module 4: Dashboard design</h3>

<p>Audience is King. Know your audience.</p>

<ul>
<li>Who is using it?</li>
<li>Are they technical or prefer dumbed down answers? Are they intimate with data?</li>
<li>What is primary objective? What questions that they try to answer? What questions this dashboard MUST answer?</li>
<li>What impact of the answer? How will they use metrics? (Role, what decisions they make)</li>
<li>When will the dashboard is used? (Weekly? Daily?) Dashboard is exploratory or explanatory?</li>
<li>What level of confidence in data sources?</li>
</ul>


<p>Dashboard layout: F layout is the most natural for web/desktop viewing.</p>

<h3>Module 5 &amp; 6: Tableau</h3>

<p>Connecting to Data:
You can connect to Excel, text file (csv or tab), or HP Vertica.
You can specify data import like Excel or using Custom SQL.
After importing, Tableau may import all data into its own internal data engine (with compression, data reorganization easier for analytics).
It also divides data into dimensions and measures.
Dimensions are further categorized into: geographic (e.g., region, postal code), number, text, date (e.g., calendar, order_date).
Facts are usually numbers but it can be other categories: e.g., geographic for latitude/longitude measures.</p>

<p>Visualizing data:
Tableau has “Show Me” button that gives suggestions for different combinations of dimensions and fact data.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Tutorial: Dimensional Modelling]]></title>
    <link href="http://tdongsi.github.io/SqlTests/blog/2016/09/15/tutorial-dimensional-modelling/"/>
    <updated>2016-09-15T15:38:20-07:00</updated>
    <id>http://tdongsi.github.io/SqlTests/blog/2016/09/15/tutorial-dimensional-modelling</id>
    <content type="html"><![CDATA[<p>From Kimball group reader.</p>

<!--more-->


<h3>Dimensional Modeling for Data Warehouse</h3>

<h4>Item 1.5: Design</h4>

<p>Design items:
You need to do data profiling to keep data processed to min. One way to profile data changes is to use CDC column.
Check CDC columns: e.g. <code>last_update_ts</code>. If CDC columns are not available, work with production system DBA to add one.
Otherwise, check application log file/Message traffic.</p>

<p>Divide data into dimension and fact tables: 90% of the time the division is obvious.</p>

<ul>
<li>Dimensions: static entities in the environment

<ul>
<li>Text descriptions are obvious data going into dimension</li>
</ul>
</li>
<li>Facts: numeric observations/measurements.

<ul>
<li>Unpredictable, numeric numbers are the usual suspects.</li>
</ul>
</li>
</ul>


<p>Grain of fact table = a measurement in physical, real-world.</p>

<p>Design steps:</p>

<ul>
<li>Determine the single physical event you want to record -> fact table. Other details will follow in dimension tables.

<ul>
<li>What event is a single row in fact table representing? E.g. for fact_sale_event, the grain is literally the beep of the scanner.</li>
</ul>
</li>
<li>Strive to make facts additive.

<ul>
<li>E.g.: Sale event can go into fact table as (price, unit), but the information (sale amount, unit) contains the same information but better since sale amount (aka extended price) = price * unit.</li>
</ul>
</li>
<li>Some data can be in both. The goal is ease of use, not methodology correctness.

<ul>
<li>E.g.: Coverage amount of insurance policies can be in both dim_coverage and fact_sale_event.</li>
</ul>
</li>
</ul>


<h4>Item 1.6</h4>

<p>Bus matrix to communicate/manage dimension tables.</p>

<p>TODO: Table of bus matrix</p>

<h4>Item 1.8 Slow Changing Dimensions</h4>

<ul>
<li>Type 0: Constant. Ignore changes.</li>
<li>Type 1: Simple overwrite (best used for error correction).</li>
<li>Type 2: Create another row and save history.

<ul>
<li>The standard implementation is: surrogate key (PK), durable ID, … attributes …, effective_start_date, effective_end_date, change_reason, current_flag.</li>
</ul>
</li>
<li>Type 3: Create another column for alternate info.</li>
</ul>


<h4>Item 1.10 Fact tables</h4>

<p>Data warehouse is built on fact tables expressed at the lowest possible grain.
Higher grain aggregated tables such as category sales by district.</p>

<p>Three kinds of fact tables:</p>

<ol>
<li>Transaction Grain: corresponds to a measurement taken at a single instant.

<ol>
<li>Unpredictably sparse or dense.</li>
<li>Can be enormous. Cannot guarantee all possible foreign keys represented.</li>
<li>E.g.: fact_qbo_subscription_event</li>
</ol>
</li>
<li>Periodic Snapshot Grain: corresponds to a predefined span of time.

<ol>
<li>Predictably dense.</li>
<li>Can be large even there is no activity.</li>
<li>E.g.: Account balance for an account at some time.</li>
</ol>
</li>
<li>Accumulating Snapshot Grain.

<ol>
<li>Fact entries are overwritten and udpated.</li>
<li>E.g.: Order processing</li>
</ol>
</li>
</ol>


<p>Surrogate Keys (integer key, assigned in sequence) are recommended for Fact tables.
In Vertica, CREATE SEQUENCE.</p>

<h4>Item 4.1: Interview for requirements</h4>

<p>Too smart interviewers make it harder to extract requirements from business:</p>

<ul>
<li>Long-winded questions</li>
<li>Even worse, some questions box the interviewee into a corner because of some bias. And the interviewees do not know how to get out.

<ul>
<li>Just ask and listen. Let them guide you step by step.</li>
</ul>
</li>
</ul>


<h4>Item 5.1-5.3: Compare normalized modeling (3NF) vs dimensional modeling (DM)</h4>

<p>Why dimensional modeling over normalized modeling?</p>

<ol>
<li>Normalized modeling is intended for transactional databases, making update and delete efficient. It’s not needed in BI/DW.</li>
<li>Normalized modeling for a complex business process will result in a very large ER diagram (similar to US cities-freeway maps). Business users cannot simply use that diagram to query what they need to know.

<ol>
<li>The result ER diagram is usually overwhelming and cannot be viewed in its entirety.</li>
<li>E.g.: How to drive from SJ to NY? Maybe going to Sacramento through 580, then to Salt Lake City, and then what? Joining tables in 3NF modeling is similar: you need to know which 10+ intermediate tables to join.</li>
<li>In the same analogy, it’s actually worse to join the tables since the tables are not static, they are moving cities.</li>
</ol>
</li>
</ol>


<p>Dimensional Modeling: top-down design process.</p>

<ul>
<li>Each fact table represents a business process.</li>
<li>Support two operations: browse and multi-table joins.</li>
<li>It is important to keep the dimension tables flat, without being normalized into snowflake structure.</li>
</ul>


<h3>Interview Questions</h3>

<p><a href="http://learndatamodeling.com/blog/data-modeling-interview-questions/">http://learndatamodeling.com/blog/data-modeling-interview-questions/</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[System Design Questions]]></title>
    <link href="http://tdongsi.github.io/SqlTests/blog/2016/09/14/system-design-questions/"/>
    <updated>2016-09-14T02:13:01-07:00</updated>
    <id>http://tdongsi.github.io/SqlTests/blog/2016/09/14/system-design-questions</id>
    <content type="html"><![CDATA[<p>How to practice for System Design questions and some design questions.</p>

<!--more-->


<h3>Readings</h3>

<p>For Web Services, read &ldquo;Architecting in AWS&rdquo;: recognize scalability problems that AWS services trying to address and replace, for example, &ldquo;AWS Load Balancer&rdquo; with generic load balancer.</p>

<p>Read these to know the broad topics that are expected.</p>

<ol>
<li><a href="https://www.quora.com/What-system-design-distributed-systems-+-scalability-topics-should-I-study-in-order-to-adequately-prepared-for-a-Google-Software-Engineer-interview">Quora question</a></li>
<li><a href="https://www.linkedin.com/pulse/technical-design-interview-guide-success-joey-addona">The Technical Design Interview - A Guide to Success</a></li>
<li><a href="https://www.linkedin.com/pulse/test-design-architecture-interview-tips-success-kane-ho">Test Design &amp; Architecture Interview - Tips to success</a></li>
</ol>


<h3>Questions</h3>

<ol>
<li>Design a simple file system using OO programming. Just folder and files.</li>
<li>How to design a load balancer?</li>
<li>How to design Facebook News Feed?</li>
</ol>


<h3>Answers</h3>

<p>(1) Design a simple file system using OO programming. Just folder and files.</p>

<p>Use Composite pattern.</p>

<pre><code class="java">class FileNode {
  String name;
}

class File extends FileNode {
  long size;
}

class Folder extends FileNode {
  Collection&lt;FileNode&gt; children;
}
</code></pre>

<p>(2) How to design a load balancer?</p>

<p>Simple: hash and assign random. What are pros and cons?</p>

<p>(3) Design Facebook News Feed.
From <a href="https://www.reddit.com/r/cscareerquestions/comments/4ytbz3/design_facebook_news_feed_my_solution_to_the/">here</a>:</p>

<p>First some numbers to get the scale of the problem:</p>

<ul>
<li>number of users: 10<sup>9</sup></li>
<li>number of users during a peak hour (upper bound): 10<sup>8</sup></li>
<li>number of posts during a peak hour: 10<sup>6</sup></li>
<li>number of other activities during a peak hour (likes, comments, saves): 10<sup>10</sup></li>
<li>almost all users have less than 10<sup>3</sup> friends</li>
</ul>


<p>The News Feed is constructed mainly based on the activity of user&rsquo;s important Facebook friends.
An important friend is a user who is my friend and I have interacted with him/her at least somewhat during recent months.
Interaction might include liking his/her comment, commenting on their post, chatting together, being marked on the same photo, etc.
We assume the backend maintains the list of important friends.
It might be updated perhaps every 60 minutes.
This ordering might be quite fuzzy.
Random perturbations of this ordering might lead to users being able to rediscover friends who they have mostly stopped interacting with.
The primary purpose of distinguishing important friends is to make the feed more interesting.
Another advantage is reduction of hotspots: there might be people with >10<sup>4</sup> friends, but we assume that every Facebook user has at most 10<sup>2</sup> important friends.</p>

<p><strong>Minimum Viable Product</strong>: The Facebook News Feed of each user is a merge of the recent posts made by all his/her important friends sorted by the score of the post.
The score of the post is ideally proportional to how interesting the post is to our user.
The score depends on: how old the post is (older posts are less interesting), how many likes the post received, how many likes the post received from user&rsquo;s important friends or friends, &hellip;</p>

<p>We primarily care about delivering an interesting News Feed. On the other hand, we don&rsquo;t really care about being able to produce an infinitely long News Feed. If our infrastructure implies that the feed is limited to 10<sup>00</sup> items and the user cannot scroll further. There are very few legitimate uses for having infinitely scrollable feed.</p>

<p>Overview of the infrastructure:</p>

<ul>
<li>Firewall</li>
<li>Load balancer</li>
<li>Front-end web servers</li>
<li>Memcache servers or Redis servers or something similar</li>
<li>Distributed database servers</li>
</ul>


<p>Let&rsquo;s see what happens when the user requests his News Feed:</p>

<ul>
<li>The request is specified by: the id of user whose feed we&rsquo;re displaying and the number N of requested posts.</li>
<li>The load balancer redirects the request to one of the web servers. It also decrypts the request. Within the datacenter, we only use unencrypted connections. To do the above, the load balancer keeps statistics of the numbers of requests each server is handling. Possibly, the load balancer might decide to start up a new server or schedule a shutdown of a server to save power. The web server checks if the user is authenticated. This is done by retrieving user&rsquo;s session data from a Google BigTable. If not logged in, s/he is redirected to the login page. If N is too large and not coming from a verified computer (like Facebook&rsquo;s API server), we reject the request and log information about a suspicious request.</li>
<li>The web server queries memcache for the list of important friends of the user in question.</li>
<li>Almost always, memcache will have this list ready in memory for all users who are currently logged in (after login, we immediately prefetch this data into memcache). The peak number of users is 10<sup>8</sup>, the number of important users at most 10<sup>2</sup>, each user is represented by an 8 byte identifier. This is an upper bound of 10<sup>11</sup> bytes, which is 100 GB of memory. Even with significant overhead, room for growth and a safety factor for situations when an unexpectedly large number of users logs in at the same time (e.g., when presidential election results are announced), this can still be stored in operating memory of a single server. A distributed memcache implementation is not going to have a problem here. For each important friend, the web server sends a request for this friend&rsquo;s Activity List. Activity List is a list of his posts, likes, comments, uploaded photos, instances of being marked on a photo, etc. Each item contains a timestamp (32 bits), item type (post, comment, share, &hellip;), id of the item (e.g., the id of the post or comment), the destination id (for example, the id of the post on which the comment was made) and privacy setting (1 byte). This is 22 bytes in total. Only identifiers are stored. The data are populated at the end of the computation.</li>
<li>These lists are stored in a distributed database hidden behind caching servers. There is 10<sup>9</sup> users, each has at most 10<sup>3</sup> items in their Activity List. This is 22 * 10<sup>12</sup> = 22 TB of memory. <strong> It is certainly possible to store this in a distributed file system. </strong>A distributed memcache on 128 servers each with 250 GB RAM would also handle this. Therefore, we can assume all these lists are almost always in memory.</li>
<li>Each item in each of these lists is assigned Relevancy Value. This depends on: The importance of the friend from whose Activity List the item is. How recent the item is. The number of likes and shares the item has (this only makes sense in the case of posts or photos). The number of likes from the user&rsquo;s other important friends. Surely, a like from 3 of my friends is more important than 10 likes from random strangers. We can access this information since we have retrieved the Activity Lists of every single important friend of the user. Since these lists include their likes and the ids of liked posts, we can specifically compute the numbers from the retrieved data. The user&rsquo;s prefered content type. Some users might like photos more than text. We remember this for each user and adjust the weight accordingly. Private posts that should not be visible to the user are removed at this point.</li>
<li>We sort each of these lists using the Relevancy Value and merge them.</li>
<li>We send this list to a content service. This service replaces all identifiers with the corresponding content (text, image links, names of users instead of user ids, &hellip;)</li>
<li>The web server uses a template to convert this into HTML.</li>
</ul>


<p>There are two questions to ponder:</p>

<ul>
<li>When the News Feed is requested again in the future, do we recalculate it from scratch? We could store the sequence calculated in one of the last steps in cache and only compute the beginning of the feed (that is: we would only compute what is new). This might make almost-infinite scrolling possible in certain cases. However, we would need to handle some corner cases. For example, the list is only approximately ordered according to the timestamp.</li>
<li>The above described the read path. It remains to analyze the write path: what happens when a user submits a content, likes something, etc. Well, we simply add this to his Activity List. In the case of posts, images, &hellip; we also store it on a content service server.</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Tutorial: Process Synchronization]]></title>
    <link href="http://tdongsi.github.io/SqlTests/blog/2016/09/06/tutorial-process-synchronization/"/>
    <updated>2016-09-06T00:35:03-07:00</updated>
    <id>http://tdongsi.github.io/SqlTests/blog/2016/09/06/tutorial-process-synchronization</id>
    <content type="html"><![CDATA[<p>Summary of chapter 5 of &ldquo;Operating System concepts&rdquo; (Dinosaur book).
Topics in this chapter are the most intensive and frequently asked during interviews.</p>

<!--more-->


<p>This chapter discuss how to prevent concurrent access to shared data that may result in data inconsistency.</p>

<h3>5.1 &amp; 5.2: Critical section</h3>

<p>Consider the producer–consumer problem, which is representative of
operating systems. Specifically, in Section 3.4.1, we described how a bounded
buffer could be used to enable processes to share memory.</p>

<pre><code class="cpp Producer process">while (true ) {

  /* produce an item in next produced */
  while (counter == BUFFER SIZE )
    ; /* do nothing */

  buffer[in] = next produced;
  in = (in + 1) % BUFFER SIZE ;
  counter++;
}
</code></pre>

<pre><code class="cpp Consumer process">while (true ) {
  while (counter == 0)
    ; /* do nothing */

  next consumed = buffer[out];
  out = (out + 1) % BUFFER SIZE ;
  counter--;
  /* consume the item in next consumed */
}
</code></pre>

<p>The above code works incorrectly in multi-thread or process situation, due to parallel modifications to &ldquo;counter&rdquo;.
When several processes access and manipulate the same data concurrently and the
outcome of the execution depends on the particular order in which the access
takes place, is called a race condition.</p>

<p>Critical section: No two processes are executing in their critical sections at the same time.
Solution to a critical section problem requires:
Mutual exclusion: only one process in CS at a time.
Progress: Selection process should not be postponed indefinitely.
Bounded waiting: once a process request to enter, waiting time is bounded.</p>

<p>Nonpreemptive kernel does not allow a process running in kernel mode to be
preempted; a kernel-mode process will run until it exits kernel mode, blocks,
or voluntarily yields control of the CPU. A nonpreemptive kernel is essentially free from race conditions.
A preemptive kernel may be more responsive, since there is less risk that a
kernel-mode process will run for an arbitrarily long period.</p>

<h3>5.3: Peterson&rsquo;s algorithm</h3>

<pre><code class="cpp Peterson's algorithm">flag[i] = true
turn = j

while ( flag[j] &amp;&amp; turn == j ) {
}

// start of CS

// end of CS
flag[i] = false flag[j] = true
turn = i

while( flag[i] &amp;&amp; turn == i ) {
}

// start of CS

// end of CS
flag[j] = false
</code></pre>

<p>NOTE: <a href="http://en.wikipedia.org/wiki/Peterson's_algorithm">Peterson’s algorithm</a> is restricted to two processes.
Filter algorithm: Peterson&rsquo;s algorithm for N processes
The filter algorithm generalizes Peterson&rsquo;s algorithm for N processes. It uses N different levels - each represents another &lsquo;waiting room&rsquo;, before the critical section. Each level will allow at least one process to advance, while keeping one process in waiting.</p>

<p><a href="http://cs.stackexchange.com/questions/12621/understanding-peterson-s-and-dekker-s-algorithms">http://cs.stackexchange.com/questions/12621/understanding-peterson-s-and-dekker-s-algorithms</a>
Both processes indicates if the other want to enter CS, it can proceed. If both processes enter at the same time, turn will be set to i and j at the same time, and only one will last.
Proof of bounded waiting: Pi will enter the CS after at most one entry by Pj.</p>

<pre><code class="plain Analogies of Peterson's algorithm">Peterson's: "I want to enter."                 flag[0]=true;
            "You can enter next."              turn=1;
            "If you want to enter and          while(flag[1]==true&amp;&amp;turn==1){
            it's your turn I'll wait."         }
            Else: Enter CS!                    // CS
            "I don't want to enter any more."  flag[0]=false;

Dekker's:   "I want to enter."                 flag[0]=true;
            "If you want to enter              while(flag[1]==true){
             and if it's your turn               if(turn!=0){
             I don't want to enter any more."      flag[0]=false;
            "If it's your turn                     while(turn!=0){
             I'll wait."                           }
            "I want to enter."                     flag[0]=true;
                                                 }
                                               }
            Enter CS!                          // CS
            "You can enter next."              turn=1;
            "I don't want to enter any more."  flag[0]=false;
</code></pre>

<h3>5.4: Sync using hardware</h3>

<p>Protect critical section by locking.</p>

<p>Many modern computer systems therefore provide special hardware
instructions that allow us either to test and modify the content of a word or
to swap the contents of two words atomically—that is, as one uninterruptible unit.</p>

<p>Atomic test_and_set() and compare_and_swap() for locking:</p>

<p>boolean test_and_set(boolean <em>target) {
boolean rv = </em>target;
*target = true;
return rv;
}</p>

<p>int compare_and_swap(int <em>value, int expected, int new value) {
int temp = </em>value;
if (<em>value == expected)
    </em>value = new value;
return temp;
}</p>

<p>Simple Mutex with atomic test_and_set()
Figure 5.5</p>

<p>Bounded-Waiting mutex with atomic test_and_set(): data structure and algorithm
Figure 5.7</p>

<h3>5.5: Mutex locks</h3>

<p>We use the mutex to lock to protect critical regions and thus prevent race conditions.</p>

<p>Calls to either acquire() or release() must be performed atomically.</p>

<p>acquire() {
while (!available)
; /<em> busy wait </em>/
available = false;
}</p>

<p>release() {
available = true;
}
Usage:</p>

<p>acquire()</p>

<p>// start of CS</p>

<p>// end of CS</p>

<p>release()</p>

<p>The main disadvantage of the implementation given here is that it requires busy waiting. This type of mutex lock is also called a spinlock.
Spinlocks do have an advantage, however, in that no context switch is required.</p>

<h3>5.6: Semaphores</h3>

<p>A semaphore S is an integer variable that, apart from initialization, is
accessed only through two standard atomic operations: wait() and signal().</p>

<p>wait(S) {
while (S &lt;= 0 )
; // busy wait
S&ndash;;
}</p>

<p>signal(S) {
S++;
}</p>

<p>The value of a counting semaphore can range over an unrestricted domain. Versus binary semaphore, which is similar to mutex.
Counting semaphores can be used to control access to a given resources of a finite number of instances.</p>

<p>We can also use semaphores to solve various synchronization problems.
For example,consider two concurrently running processes: P1 with a statement
S1 and P2 with a statement S2 . Suppose we require that S2 be executed only
after S1 has completed. We can implement this scheme readily by letting P1
and P2 share a common semaphore synch, initialized to 0. In process P1 , we
insert the statements
S1;
signal(synch);</p>

<p>In process P2 , we insert the statements
wait(synch);
S 2 ;</p>

<p>Because synch is initialized to 0, P2 will execute S2 only after P1 has invoked
signal(synch) , which is after statement S1 has been executed.</p>

<p>Deadlock:
P 0 P 1
wait(S); wait(Q);
wait(Q); wait(S);
. .
. .
. .
signal(S); signal(Q);
signal(Q); signal(S);</p>

<p>Priority inversion:
The problem of priority inversion is when three processes of different priorities L &lt; M &lt; H. H is waiting for L to finish with a certain resource. M process becomes runnable and preempts L. Indirectly, process M with lower priority affects how long process H must wait for resource.
It occurs when the system has more than two priorities. However, it is almost always the case.
Solution: priority-inheritance protocol: all processes that use a resource, waited by a higher priority process, will inherit the highest priority until they are done with the resource.</p>

<h4>Semaphore implementation</h4>

<p>The naive definition of wait() and signal() above presents the same problem of busy waiting.
In actual implementation, when a process execute wait() operation and find that semaphore value is not positive, it must wait. However, instead of busy waiting, the process block itself.
In this implementation, semaphore values may be negative, while they are never negative in classical definition with busy waiting. If a semaphore value is negative, its magnitude indicates the number of waiting processes (note different order of decrement in wait()).</p>

<p>It is critical that semaphore operations be executed atomically: no two processes can execute wait() and signal() operations on the same semaphore at the same time.
In a multiprocessor environment, usually compare_and_swap() or spin locks are used to ensure wait() and signal() are atomic.
So, we admit that busy waiting is NOT eliminated in this implementation. However, busy waiting is limited to CS of the wait() and signal() operations. These CSs are short (about 10 instructions). Thus, CS is almost never occupied, and busy waiting is rare and short, if ever happens.</p>

<h3>5.7: Classic Problems of Synchronization</h3>

<p>Use semaphores for synchronization. Actual implementation can use mutex instead of binary semaphore.</p>

<p>Bounded-Buffer (Consumer-Producer) problem
Problem: See 5.1.
Solution: The producer and consumer share the following data structure:
The mutex is used to provide mutual exclusion for accesses to the buffer pool.
int n;
semaphore mutex = 1;
semaphore empty = n;
semaphore full = 0</p>

<p>Producer    Consumer
do {
&hellip;
/<em> produce an item in next produced </em>/
&hellip;
wait(empty);
wait(mutex);
&hellip;
/<em> add next produced to the buffer </em>/
&hellip;
signal(mutex);
signal(full);
} while (true);
do {
wait(full);
wait(mutex);
&hellip;
/<em> remove an item from buffer to next consumed </em>/
&hellip;
signal(mutex);
signal(empty);
&hellip;
/<em> consume the item in next consumed </em>/
&hellip;
} while (true);</p>

<p>Reader-Writer problem:
Writers should have exclusive access while writing to the shared database.
There are several variants of “reader-writer” problems:
First problem: No reader to be kept waiting unless a writer has already obtained accesss.
Second problem: Once writer is ready, that writer perform its write ASAP. No new readers may start reading.
A solution to either problem may result in starvation.</p>

<p>Solution to first reader-writer problem: shared data structure
semaphore rw_utex = 1;
semaphore mutex = 1;
int read count = 0;
The mutex semaphore is used to ensure mutual exclusion when the variable read count is updated.
The read count variable keeps track of how many processes are currently reading the object.
The semaphore rw_mutex functions as a mutual exclusion semaphore for the writers.</p>

<p>Writer  Reader
do {
wait(rw mutex);
&hellip;
/<em> writing is performed </em>/
&hellip;
signal(rw mutex);
} while (true);
do {
wait(mutex);
read count++;
if (read count == 1)
wait(rw mutex);
signal(mutex);
&hellip;
/<em> reading is performed </em>/
&hellip;
wait(mutex);
read count&ndash;;
if (read count == 0)
signal(rw mutex);
signal(mutex);
} while (true);</p>

<p>Dining Philosopher problem: This solution can create a deadlock
semaphore chopstick[5];</p>

<p>do {
wait(chopstick[i]);
wait(chopstick[(i+1) % 5]);
&hellip;
/<em> eat for awhile </em>/
&hellip;
signal(chopstick[i]);
signal(chopstick[(i+1) % 5]);
&hellip;
/<em> think for awhile </em>/
&hellip;
} while (true);</p>

<p>Several possible remedies to the deadlock problem are replaced by:
• Allow at most four philosophers to be sitting simultaneously at the table.
• Allow a philosopher to pick up her chopsticks only if both chopsticks are
available (to do this, she must pick them up in a critical section).
• Use an asymmetric solution—that is,an odd-numbered philosopher picks
up first her left chopstick and then her right chopstick, whereas an even-
numbered philosopher picks up her right chopstick and then her left
chopstick.</p>

<p>In 5.8, we use monitor (equivalent to a waiter to tell which philosopher should eat) to provides deadlock-free solution.
A deadlock-free solution does not necessarily eliminate the possibility of starvation.</p>

<h3>5.8: Monitors</h3>

<p>Semaphore is not a complete solution. If a single process is not well-behaved (semaphore used incorrectly), the system break down.
Incorrect order of signal() and wait(): mutual exclusion is no longer guaranteed.
wait() is used in place of signal(): a deadlock may occur.
wait() or signal() or both are omitted: mutual exclusion violated or deadlock.</p>

<p>Syntax of a monitor:</p>

<p>Local variables of a monitor can be accessed by only the local functions. Only one process at a time is active within the monitor.
We also defines condition construct: condition x, y; // condition variables
The only operations that can be invoked on a condition variable are wait() and signal().
The operation x.wait(); means that the process invoking this operation is suspended until another process invokes x.signal();
The x.signal() operation resumes exactly one suspended process. If no process is suspended, then the signal() operation has no effect.
(Different from semaphore’s signal(): semaphore() signal always change the state of semaphore, condition’s signal() may not).</p>

<p>Dining Philosophers solution using Monitors:
Monitor is acting like a waiter/moderator. Before a philosopher starts eating, she informs the waiter (invoked operation pickup()) and the waiter will tell her what to do.
After she is done eating, she again informs the waiter (putdown()). It is still possible that some philosopher will starve to death.</p>

<p>condition self[5];
allows philosopher i to delay herself when she is hungry but is unable to obtain the chopsticks she needs.</p>

<p>Implement a Monitor with Semaphores
Check Section 5.8.3 page 229.</p>

<p>Resuming Processes within a Monitor
One simple solution is to use FIFO ordering.
Another solution is conditional-wait construct, with c is the priority number input.
x.wait&copy;;
When x.signal() is executed, the process with the smallest priority number is resumed next.</p>

<p>Java monitors
Java uses monitor for thread synchronization.
Every object in Java has a single lock associated with it. When a method is declared synchronized, calling the method requires owning the lock of the object.
If the lock is not available, the synchronized method is placed in the entry set for the object’s lock.
The Java Object class’s method wait() and notify() are similar to wait() and signal() statements for a monitor.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Tutorial: Estimation Theory]]></title>
    <link href="http://tdongsi.github.io/SqlTests/blog/2016/09/04/tutorial-estimation-theory/"/>
    <updated>2016-09-04T23:40:12-07:00</updated>
    <id>http://tdongsi.github.io/SqlTests/blog/2016/09/04/tutorial-estimation-theory</id>
    <content type="html"><![CDATA[<p>Math in Estimation theory.</p>

<!--more-->


<h3>Basic statistics</h3>

<p>Two vectors <strong>x</strong> and <strong>z</strong> is joinly Guassian when the combined vector <strong>y</strong> = [x z] is also Gaussian.
Jointly Gaussian implies marginally Guassian, conditionally Gaussian. The reverse is not true.</p>

<p><a href="https://en.wikipedia.org/wiki/Simpson%27s_paradox">Simpson’s paradox</a>: e.g. Warriors is first in 2P% and 3P% in NBA season 2016, but not first in FG%.
The first team in FG% is Spurs, who took lots of 2s.</p>

<h3>Basic Kalman Filter</h3>

<p>TODO</p>

<h4>Kalman Filter</h4>

<h4>Extended Kalman Filter</h4>

<h3>EKF-SLAM formulation</h3>

<p>TODO</p>

<h3>Mingyang&rsquo;s thesis</h3>

<p>Contributions:</p>

<ol>
<li>Analysis of EKF-SLAM and MSCKF. New estimator (MSCKF 2.0) with correct observability.</li>
<li>Hybrid estimator that picks either EKF-SLAM formulation or MSCKF 2.0, depending on length of feature tracks.</li>
<li>Online calibration of the spatial and temporal relationship between visual and inertial sensors.</li>
<li>Sensor models for rolling shutter cameras and low-cost inertial sensors.

<ol>
<li>IMU axis misalignment, scale factors, and g-sensitivity affects inertial sensors.</li>
<li>Image distortions from rolling shutter cameras.</li>
</ol>
</li>
</ol>


<p> Why? IMU and cameras are already found in several commercial resource-constrained devices (e.g., mobile phones and AR devices).</p>

<h4>Contribution 1: EKF-SLAM and MSCKF -> MSCKF 2.0</h4>

<p>EKF-SLAM formulation: current pose + feature positions.
Since we are not doing mapping, only currently visible features are kept -> computational cost is bounded.</p>

<p>MSCKF: a sliding window of poses.
Measurements are used to impose the constraints on these poses.
If a new feature is found, add a new pose to the state vector and augment covariance matrix accordingly.
Each feature is tracked until it goes out of field of view, then all of its observations are processed at once.
A pose is only removed when all features associated with that pose have been processed.</p>

<p>Consistency and accuracy of estimators are correlated.
A recursive estimator is consistent if the estimation errors are zero-mean and have covariance matrix as reported by the estimator.</p>

<p>Why difference? Assumptions:</p>

<ul>
<li>In EKF: IMU state and feature positions are jointly Gaussian. With non-linear measurement models, this is a strong assumption.

<ul>
<li>To improve it, need to pick another feature parameterization to make the measurement model closer to linear.</li>
</ul>
</li>
<li>In MSCKF, there is no feature positions. No assumptions on feature positions are required.</li>
<li>MSCKF delay linearization: only process each feature when all of its measurement are available -> better estimates -> better Jacobians -> better updates.</li>
<li>In EKF-SLAM, using fewer observations: e.g., in standard XYZ parameterizaton, it can lead to wildly inaccurate estimates.</li>
</ul>


<h4>Contribution 2: Hybrid estimator, pick one</h4>

<ul>
<li>N: number of features.</li>
<li>m: feature length: max number of observations per feature.</li>
</ul>


<p>Then, the compuational costs of the two estimators are</p>

<ul>
<li>MSCKF: O(N) and O(m<sup>3</sup>).</li>
<li>EKF-SLAM: O(N<sup>3</sup>) and O(m).</li>
</ul>


<p>MSCKF is faster because of general distribution of features: because of feature detection algorithms, majority of features are detected close to the camera, where it will goes out of the FOV quickly (large N, small m).
For example, in Cheddar Gorge data, many features are close to the car/camera, while a few are really far away.</p>

<p>Depending on the length of feature tracks in current environment, use one.
Given “many” measurements, nothing is gained by initializing features  observed fewer than m times.
So, if the features is observed less than m times, use MSCKF. Otherwise, put it in the state vector and use EKF-SLAM.
m (sliding window size) is to determined empirically: plotting and see the low points.</p>

<h4>Contribution 3: Online camera-to-IMU calibration</h4>

<p>Detailed identifiability analysis of these parameters.
Time offset between the two measurements.
The degenerate cases are known and rare cases.</p>

<p>Some degenerate cases are: (Recovery?)</p>

<ul>
<li>Going in a straight line</li>
<li>Constant acceleration with no rotation</li>
<li>Constant velocity (no acceleration) with rotation about gravity vector only.</li>
</ul>


<h4>Contribution 4: Models for low-cost sensors</h4>

<p>Measurement models for rolling shutter camera.</p>
]]></content>
  </entry>
  
</feed>
